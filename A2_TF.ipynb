{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from re import search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_FREQUENCY = 48_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kenny/Area_2_Trabalho_Final/48k_DE/'\n",
    "\n",
    "size_sample = 2048\n",
    "df_original = pd.DataFrame()\n",
    "\n",
    "for entry in os.scandir(path):\n",
    "    if entry.is_file():\n",
    "        mat = scipy.io.loadmat(path+entry.name)\n",
    "        for i in mat.keys():\n",
    "            if search('DE',i):\n",
    "                key = i\n",
    "\n",
    "        raw_data = [item for sublist in mat[key] for item in sublist]\n",
    "\n",
    "        samples = [raw_data[i*size_sample:(i+1)*size_sample] for i in range(int(len(raw_data)/2048))]\n",
    "        df_original_raw = pd.DataFrame(zip(samples),columns=['Samples'])\n",
    "        df_original_raw['Fault'] = entry.name.split('.')[0].split('_')[0]\n",
    "        df_original = pd.concat([df_original,df_original_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy(deep=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "sample = 100\n",
    "y = df.iloc[sample]['Samples']\n",
    "x = np.array(range(len(y)))*1/SAMPLE_FREQUENCY\n",
    "\n",
    "fig = px.line(x=x, y=y, title=f'Sample {sample}',\n",
    "              labels={'y':'Acceleration [g]',\n",
    "                      'x':'Time [s]'\n",
    "              })\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Max'] = df.apply(lambda x: np.array(x[0]).max(),axis=1)\n",
    "df['Min'] = df.apply(lambda x: np.array(x[0]).min(),axis=1)\n",
    "df['Mean'] = df.apply(lambda x: np.array(x[0]).mean(),axis=1)\n",
    "df['RMS'] = df.apply(lambda x: np.sqrt(np.mean(np.array(x[0])**2)),axis=1)\n",
    "df['Var'] = df.apply(lambda x: np.var(np.array(x[0])),axis=1)\n",
    "df['Crest'] = df.apply(lambda x: (np.array(x[0]).max())/(np.sqrt(np.mean(np.array(x[0])**2))),axis=1)\n",
    "df['Form'] = df.apply(lambda x: np.sqrt(np.mean(np.array(x[0])**2))/np.abs(np.array(x[0])).mean(),axis=1)\n",
    "df['Impu'] = df.apply(lambda x: np.array(x[0]).max()/np.sqrt(np.mean(np.abs(np.array(x[0])))),axis=1)\n",
    "df['Clear'] = df.apply(lambda x: np.array(x[0]).max()/np.mean(np.sqrt(np.abs(np.array(x[0])))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Samples'])\n",
    "df_full = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Fault']).corr()\n",
    "corr_matrix = df.corr()\n",
    "plot = sns.heatmap(corr_matrix, annot=True)\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"images/base_corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full.drop(columns=['Fault','Impu','Min'])\n",
    "corr_matrix = df.corr()\n",
    "plot = sns.heatmap(corr_matrix, annot=True)\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"images/base_corr_drop.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_time_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(data_time_scaled, columns=df.columns)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled,df_full['Fault'], test_size = 0.2, stratify = df_full['Fault'], random_state = 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = svc_model.predict(X_train)\n",
    "test_predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_confu_matrix = confusion_matrix(y_train, train_predictions)\n",
    "test_confu_matrix = confusion_matrix(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_type = df_full.Fault.unique()\n",
    "\n",
    "fig = plt.figure(1,figsize=(18,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(train_confu_matrix, annot= True,fmt = \"d\",\n",
    "xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(test_confu_matrix, annot = True,fmt = \"d\",\n",
    "xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "fig.savefig('images/output_SVM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report (test set)\n",
    "class_report = classification_report(y_pred = test_predictions, y_true = y_test)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"C\":[1, 10, 45, 47,49, 50, 51, 55, 100, 300, 500],\n",
    "             'gamma':[0.01, 0.05, 0.1, 0.5, 1, 5],\n",
    "             'kernel':[\"rbf\",\"linear\"]}\n",
    "\n",
    "tuned_svm_clf = GridSearchCV(SVC(),parameters,n_jobs = -1, cv= 10)\n",
    "tuned_svm_clf.fit(train_data_scaled, train_data['fault'])\n",
    "\n",
    "print(tuned_svm_clf.best_params_)\n",
    "print(tuned_svm_clf.best_estimator_)\n",
    "\n",
    "train_predictions_best = tuned_svm_clf.best_estimator_.predict(train_data_scaled)\n",
    "test_predictions_best = tuned_svm_clf.best_estimator_.predict(test_data_scaled)\n",
    "\n",
    "train_confu_matrix_best = confusion_matrix(train_data['fault'], train_predictions_best)\n",
    "test_confu_matrix_best = confusion_matrix(test_data['fault'], test_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(18,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(train_confu_matrix_best, annot= True,fmt = \"d\",\n",
    "xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
    "plt.title('Training Confusion Matrix (best model)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(test_confu_matrix_best, annot = True,\n",
    "            xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
    "plt.title('Test Confusion Matrix (best model)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "class_report_best = classification_report(y_pred = test_predictions_best, y_true = test_data['fault'])\n",
    "print(class_report_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "logis_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logis_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_lr = logis_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_confu_matrix_lr = confusion_matrix(y_test, test_predictions_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "class_report_lr = classification_report(y_pred = test_predictions_lr, y_true = y_test)\n",
    "print(class_report_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions\n",
    "train_predictions_logis = logis_model.predict(X_train)\n",
    "test_predictions_logis = logis_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report (test set)\n",
    "class_report_logis = classification_report(y_pred = test_predictions_logis, y_true = y_test)\n",
    "print(class_report_logis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,6))\n",
    "\n",
    "sns.heatmap(test_confu_matrix_lr, annot = True,\n",
    "xticklabels=fault_type, yticklabels=fault_type,fmt = \"d\", cmap = \"Blues\", cbar = False)\n",
    "plt.title('Test Confusion Matrix (logistic regression)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='relu',input_shape=(len(X_train.columns),)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=len(df['Fault'].unique()), activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['Fault'].unique())\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model.fit(x = X_train, y = y_train_transformed, epochs=400, validation_data = (X_test, y_test_transformed),verbose=1, callbacks=[early_stop])\n",
    "model_history = pd.DataFrame(model.history.history)\n",
    "ax = model_history.plot()\n",
    "ax.set_xlabel('Época')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "# Define the model\n",
    "def create_model(unitsA=10, unitsB=10, optimizer = 'adam', learning_rate=0.01, loss='sparse_categorical_crossentropy', metrics=['accuracy']):\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adamax':\n",
    "        optimizer = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=unitsA, activation='relu',input_shape=(len(X_train.columns),)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=unitsB, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=len(df['Fault'].unique()), activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {'optimizer': ['sgd', 'rmsprop', 'adagrad', 'adamax', 'adam'],\n",
    "              'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "              'unitsA': list(range(1,100,10)),\n",
    "              'unitsA': list(range(1,100,10)),\n",
    "              }\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(KerasClassifier(model=create_model, epochs=1), \n",
    "                           param_grid=param_grid, cv=3, n_jobs=-1,\n",
    "                           validation_data = (X_test, y_test),verbose=1, callbacks=[early_stop])\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and their corresponding score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "568a6ae751fd6e62f855d3b85aebb8a31a96d83a4cd1f170dc912566c8777b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
